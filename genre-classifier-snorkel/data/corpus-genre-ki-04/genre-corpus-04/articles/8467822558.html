<!-- <DOCUMENT>
	<FILE>
		8467822558.html
	</FILE>
	<URL>
		http://excalibur.brc.uconn.edu/~baynet/pragmatics.html
	</URL>
	<TITLE>
		Bayesian Networks Pragmatics
	</TITLE>
	<GENRE>
		articles
	</GENRE>
	<PLAINTEXT>
 Bayesian Networks Pragmatics I.D.I.S. Artificial Intelligence Resources Bayesian Networks Pragmatics This page provides discussions on the pragmatics of building and using Bayesian Networks. Special thanks for Russ Greiner ( greiner@scr.siemens.com ) for gathering much of this information. Table of Contents Why Bayesian Networks? Knowledge Acquisition/Engineering General Discussion Why Bayesian Networks? From Knowledge Industries home page - Comparison with Rule-Based Expert Systems: [...], it is worth pointing out some differences between traditional expert systems and probability-based diagnosis systems. In an expert system, the knowledge engineer attempts to capture the reasoning process of that an expert uses during diagnosis. Probability-based systems, on the other hand, capture the expert's qualitative physical understanding of the system under diagnosis and use this knowledge to construct diagnostic models. While it is possible to capture diagnostic information directly in a probabilistic system, our experience shows that it is much faster and easier to assess causal models. Eric Horvitz ( horvitz@microsoft.com ) writes: One of the strongest reasons is that uncertainty is indeed prevalent in the real world and it is critical to represent that uncertainty in at least a semi-coherent manner. Another reason is that Bayesian networks are a fundamentally more modular representation of uncertain knowledge than rule-based systems. This makes them easier to maintain, and to adapt them to different contexts, than there rule-based relatives. [...] The uncertain decision making context, and the modularity and ease of maintenance, make the Bayesian networks quite attractive. [..] Bayesian networks are very intuitive for nonexperts. We had a United Airlines engine person drawing and debugging these models within a few hours of exposure to them. The NASA Vista people needed to have a way to fuse together the implications of multiple sensors, some noisy, when we began the Vista project. There was no good way to take into consideration all of the sensors and their failure modes with a fault tree. Bruce D'Ambrosio ( dambrosi@chert.cs.orst.edu ) writes: I am currently doing some work with Litton Data Systems. The strong arguments there are primarily technological: improved performance, better communication with experts (model-based reps are modular and easy to work with). Stuart Russell ( russell@cs.berkeley.edu ) writes: The commonsense case for BNs over eg NNs is the expert can provide knowledge in the form of causal structure quite easily the resulting network after training is understandable and extensible and provides probabilities on variables of interest, and can also be used easily with arbitrary missing data (in both training and use). Russ Greiner ( greiner@scr.siemens.com ) writes: I was told that many of the papers at the recent NIPS'95 Workshop on Learning in Bayesian Networks and Other Graphical Models contained (often implicit) comparisions between Bayesian nets and neural nets, especially in terms of learning. In response to I am looking for a concrete BUSINESS arguments for using Bayesian nets. In particular, it would be useful to have a host of testimonials, of the form [...] Wray Buntine ( wray@ptolemy-ethernet.arc.nasa.gov ) writes: Note on what follows: I'm all in the question and the positive responses, I'm just being flippant and trying to inject a different perspective. I always thought that concrete BUSINESS arguments for using Bayesian nets are rather like concrete BUSINESS arguments for using the product rule of calculus. Bayesian nets in the narrow sense are the kind of graph plus probability tables that have dominated UAI conferences in previous years. I'd have a hard time putting a case for these on anything but very specific narrow problems. Bayesian networks in the broader sense of "probabilistic networks" are a set of methods and representation for probabilistic calculation that applies to most problems with probabilities. On any serious sized problem, people will grind through similar operations anyway. Whether you call this Bayesian nets or not is a matter of which scientific tribe you belong to. I would never recommend a business use probabilistic networks. But I would recommend a business employ R&D people with some good graduate training in probabilistic networks. So instead, here are some more apt questions and answers I believe. I'm going to replace the phrase "Bayesian nets", by the phrase "The Magic Button" in what follows. If you object to this phrase, then use "Genetic Algorithms" or "Neural Networks" instead or any of the other magic buttons that the research community is busily constructing for industry to push. Q1. I am looking for a concrete BUSINESS arguments for using The Magic Button. A1. Put smart people on the job and have them use the right tools. Don't necessarily use The Magic Button, but if your specific problem has a need for the kind of analysis that The Magic Button can help with, then by all means push the The Magic Button. i.e., I believe there are no concrete BUSINESS arguments for using probabilistic networks in general. Q2. Should I employ an expert in The Magic Button to solve my problem. A2. Most likely "no". Most problems require a combination of different skills, database work, systems programming, Windows-UNIX interfaces, visualization, probabilistic reasoning. Have the expert act as a consultant, maybe. Now this is rather quickly starting to sound like I believe no-one should be using probabilistic networks. Course I don't believe this. For the following reasons. Probabilistic networks in the broader sense are the way to address issues of probabilistic calculation. They are unavoidable. If you are addressing any problem with uncertainty (vision, image processing, database mining, diagnosis, etc.) then you are invariably doing something that is at least a rough approximation to probabilistic computation. So if your smart people are using the right tools, then they will be using variations of probabilistic networks anyway. The question is, whether they have been properly trained in the more elegant framework of probabilistic networks, or whether they grind through the same kinds of calculations on their own. My experience is that applications out in industry aren't solved properly because FEW people are willing to go out and acquire the right tools for the particular problem they are looking at, and are rarely trained in the different neighboring fields where they could get useful ideas. Furthermore, experts in the The Magic Button run around looking for applications suited for their Magic Button, and a large pool of applications exist that require a 5% input from The Magic Button A, another 5% from The Magic Button B, another 5% from The Magic Button C, and then 85% of good old sweat and toil. So instead the relevant questions are: Q3. Are probabilistic networks the right tools for addressing uncertainty (in its many forms) ? (Rhetorical question only, don't want to start THIS discussion) Q4. If the answer to Q3 is yes, then why aren't probabilistic networks a basic option for all computer scientists, statisticians, etc., in graduate school ? Knowledge Acquisition Edward J. Wright ( EJWright@smtpgate.read.tasc.com ) writes: [We tried] to encode the "rules" for some simple photo-geology [within a public domain expert system shell]. But I could never get it to work. Later I found another expert system shell that included certainty factors. I could not get that to work either. [I recently] used the same problem as a class project for a Bayesian network class. I will emphasize that the system I built is a very simple subset of the photo-geology problem, but it does provide answers that are always reasonable and usually correct. And I spent much less time building the Bayes net model then I did playing with the rule based systems. I think the problem was too many interrelated variables and no way to deal with uncertain relationships, but this was no challenge for the Bayesian net. Eric Horvitz ( horvitz@microsoft.com ) writes: [...] thought you might find reading [ Henrion 87 ] interesting, given your recent question on rationale for using influence diagrams and belief networks. [Also] a discussion of efficiency of knowledge acquisition and modularity and its implications for maintaining knowledge bases [can be found] in [ Horvitz 88 ]. Russ Greiner ( greiner@scr.siemens.com ) writes: As the title suggests, the first article compares the challenge of building an effective diagnostic system (for the diagnosis and treatment of root disorders of apple trees) within first a standard rule-based expert system framework (ES), and then an influence diagram (ID). There were several relevant findings: The two systems produced had similar graphical structures, modulo the directions of the links. While an ID can, in principle, require a great many numbers, here the expert had to specify only a few. (Most of the values degenerated to either 0 or 1, or were determined by other values.) Moreover, a sensitivity analysis suggests that even rough assessments were usually sufficient. While it was easier to produce an *initial* ES than an ID (as the rule-based ES requires fewer numbers, etc), the ES requires more extensive testing, debugging and tuning, as the initial ES will cover only the combinations that the expert explicitly anticipated. This also means an ID can handle situations that the expert did expect, perhaps better than the initial expert could have. The second article is also superb. Among other things, it discusses the need for handling uncertainties, motivates the use of probabilities and decision theory, and reviews some early attempts. It also states that "although recent research on the application of decision-science seems promising, for the most part only prototype systems have been demonstrated" General Discussion Expert Systems and Probabilistic Network Models (1997) E. Castillo, J. M. Gutirrez, and A. S. Hadi. Springer-Verlag, New York. Spanish version: Sistemas Expertos y Modelos de Redes Probabilsticas (1997) E. Castillo, J. M. Gutirrez, and A. S. Hadi. Monografas de la Academia Espa1ola de Ingeniera, Madrid. Symbolic Propagation Algorithms: "Sensitivity Analysis in Discrete Bayesian Networks" (1997) E. Castillo,J.M. Gutirrez, and A.S. Hadi IEEE Transactions on Man, Cybernetics and Systems 27(4), 403-412. "A new Method for Symbolic Propagation in Bayesian Networks" (1996) E. Castillo,J.M. Gutirrez, and A.S. Hadi Networks 28, 31-43. Learning: "Learning and Updating of Uncertainty in Dirichlet Models" (1997) Castillo, E., Hadi, A. S., and Solares, C. Machine Learning, in press. Modeling Continuous and Discrete-Continuous Models: "Modeling Networks of Discrete and Continuous Variables with an Application to Damage Assessment" (1997) E. Castillo,J.M. Gutirrez, and A.S. Hadi Multivariate Analysis, in press. "Symbolic Propagation and Sensitivity Analysis in Gaussian Bayesian Networks with Application to Damage Assessment" (1997) E. Castillo,J.M. Gutirrez, and A.S. Hadi Artificial Intelligence in Engineering 11, 173-181. Administrator: Dr. Eugene Santos --- eugene@cse.uconn.edu Webmaster: Mitchell Saba --- saba@cse.uconn.edu Last Update: 
	</PLAINTEXT>
	<CONTENT>
-->
<HTML>

	<HEAD>
		<title>
			Bayesian Networks Pragmatics
		</title>
	</HEAD>

	<BODY background="images/backgrounds/idis-bg.gif" border=0>

<Center>
<Table border=15 cellspacing=20 cellpadding=10 width=75%>
		<TR>
		<TD align=center valign=middle rowspan=2>
					<img src="images/idis.gif" width=125 alt="logo">
				</TD>
				<TD align=center valign=middle>
					<FONT Size=3><B>
						I.D.I.S.
					</B></FONT>
					<BR>
					<FONT Size=4><B>
						Artificial Intelligence Resources
					</B></FONT>
				</TD>
			</TR>
			<TR>
				<TD align=center valign=middle>
					<FONT Size=7 color="#800000"><B>
						Bayesian Networks
						Pragmatics
					</B></FONT>
				</TD>
		</TR>
</Table>
</Center>

<hr size=5>

<FONT Size=4>

		This page provides discussions on the pragmatics of building and
		using Bayesian Networks. Special thanks for Russ Greiner
			(<A href="mailto:greiner@scr.siemens.com">greiner@scr.siemens.com</A>)
		for gathering much of this information.

<hr size=5>

<CENTER>

<TABLE border=5 cellspacing=10 cellpadding=5 width=75%>
				<TH align=center valign=middle colspan=2>
					<FONT size=5 color="#800000">
						<B> Table of Contents </B>
					</FONT>
				</TH>

				<TR>
					<TD align=center valign=middle>
<A href="#WHY"><img src="images/buttons/smbutton.gif" border=0 align=middle></A>
					</TD>
					<TD align=center valign=middle>
						Why Bayesian Networks?
					</TD>
				</TR>

				<TR>
					<TD align=center valign=middle>
<A href="#KNOWLEDGE"><img src="images/buttons/smbutton.gif" border=0 align=middle></A>
					</TD>
					<TD align=center valign=middle>
						Knowledge Acquisition/Engineering
					</TD>
				</TR>

				<TR>
					<TD align=center valign=middle>
<A href="#GENERAL"><img src="images/buttons/smbutton.gif" border=0 align=middle></A>
					</TD>
					<TD align=center valign=middle>
						General Discussion
					</TD>
				</TR>
			</Table>

		</CENTER>

		<P>

		<hr size=5>

		<P>

		<A name="WHY"></A>
		<Center>
			<Table border=5 cellspacing=10 cellpadding=10>
				<TR>
					<TH align=center valign=middle>
						Why Bayesian Networks?
					</TH>
				</TR>

				<TR>
				</TR>

				<TR>
					<TD align=left valign=middle>

From <!-- A href="http://www.kic.com/belnet.htm" -->Knowledge Industries</A> 
home page -

<P>

Comparison with Rule-Based Expert Systems:

	<UL>
		<LI>
   [...], it is worth pointing out some differences between traditional
   expert systems and probability-based diagnosis systems.  In an expert
   system, the knowledge engineer attempts to capture the reasoning process of
   that an expert uses during diagnosis.  Probability-based systems, on the
   other hand, capture the expert's qualitative physical understanding of the
   system under diagnosis and use this knowledge to construct diagnostic
   models.  While it is possible to capture diagnostic information directly in
   a probabilistic system, our experience shows that it is much faster and
   easier to assess causal models.
	</UL>

					</TD>
				</TR>

				<TR>
					<TD align=left valign=middle>

Eric Horvitz (<a href="mailto:horvitz@microsoft.com">horvitz@microsoft.com</A>) writes:

<UL>
	<LI>

  One of the strongest reasons is
  that uncertainty is indeed prevalent in the real world and it is
  critical to represent that uncertainty in at least a semi-coherent
  manner.   Another reason is that Bayesian networks are a fundamentally
  more modular representation of uncertain knowledge than rule-based
  systems.  This makes them easier to maintain, and to adapt them to
  different contexts, than there rule-based relatives.
	<P>
  [...]
	<P>
  The uncertain decision making context, and the modularity and ease of
  maintenance, make the Bayesian networks quite attractive.
	<P>

  [..]

	<P>
  Bayesian networks are very intuitive for nonexperts.   We had a United
  Airlines engine person drawing and debugging these models within a few
  hours of exposure to them.

	<P>
  The NASA Vista people needed to have a way to fuse together the
  implications of multiple sensors, some noisy, when we began the Vista
  project.  There was no good way to take into consideration all of the
  sensors and their failure modes with a fault tree.
</UL>

					</TD>
				</TR>

				<TR>
					<TD align=left valign=middle>
Bruce D'Ambrosio (<a href="mailto:dambrosi@chert.CS.ORST.EDU">dambrosi@chert.cs.orst.edu</A>) writes:

<UL>
	<LI>

  I am currently doing some work with Litton Data Systems.  The strong
  arguments there are primarily technological: improved performance,
  better communication with experts (model-based reps are modular and
  easy to work with).
</UL>
					</TD>
				</TR>

				<TR>
					<TD align=left valign=middle>
Stuart Russell (<a href="mailto:russell@CS.Berkeley.EDU">russell@cs.berkeley.edu</A>) writes:

	<UL>
		<LI>
  The commonsense case for BNs over eg NNs is
	<OL>
		<LI> the expert can provide knowledge in the form of causal structure
			quite easily
  		<LI> the resulting network after training is understandable and
			extensible and provides probabilities on variables of interest, and
			can also be used easily with arbitrary missing data (in both
			training and use).
	</OL>
	</UL>

					</TD>
				</TR>

				<TR>
					<TD align=left valign=middle>
Russ Greiner (<A href="mailto:greiner@scr.siemens.com">greiner@scr.siemens.com</A>) writes:

	<UL>
		<LI> I was told that many of the papers at the recent

		<UL>
			<LI> <a href="http://www.research.microsoft.com/research/nips95bn/">NIPS'95 Workshop on Learning in Bayesian Networks and
				Other Graphical Models</A>
		</UL>
contained (often implicit) comparisions between Bayesian nets and
neural nets, especially in terms of learning.

					</TD>
				</TR>

				<TR>
					<TD align=left valign=middle>
In response to 
	<UL>
		<LI> I am looking for a concrete BUSINESS arguments for using Bayesian
			nets. In particular, it would be useful to have a host of
			testimonials, of the form [...]
	</UL>

Wray Buntine (<A href="mailto:wray@ptolemy-ethernet.arc.nasa.gov">wray@ptolemy-ethernet.arc.nasa.gov</A>) writes:

	<UL>
		<LI> Note on what follows: I'm all in the question and the positive
			responses, I'm just being flippant and trying to inject
			a different perspective.

		<LI> I always thought that concrete BUSINESS arguments for using
Bayesian nets are rather like concrete BUSINESS arguments for using
the product rule of calculus. Bayesian nets in the narrow sense are the kind of
graph plus probability tables that have dominated UAI conferences
in previous years.  I'd have a hard time putting a case for these
on anything but very specific narrow problems.   Bayesian networks in the
broader sense of "probabilistic networks" are a set of
methods and representation for probabilistic calculation that
applies to most problems with probabilities.  On any serious
sized problem, people will grind through similar operations anyway.
Whether you call this Bayesian nets or not is a matter of which 
scientific tribe you belong to.   I would never recommend a business
use probabilistic networks.   But I would recommend a business employ
R&D people with some good graduate training in probabilistic networks.
<P>
So instead, here are some more apt questions and answers I believe.
I'm going to replace the phrase "Bayesian nets", by the phrase
"The Magic Button" in what follows.   If you object to this
phrase, then use "Genetic Algorithms" or "Neural Networks" instead
or any of the other magic buttons that the research community is
busily constructing for industry to push.
	<UL>
		<LI> <B>Q1.</B> I am looking for a concrete BUSINESS arguments for 
	  using The Magic Button.
		<LI> <B>A1.</B> Put smart people on the job and have them use the right
	  tools.	Don't necessarily use The Magic Button, but
	  if your specific problem has a need for the kind of 
	  analysis that The Magic Button can help with, then
	  by all means push the The Magic Button.
<P>
i.e.,   I believe there are no concrete BUSINESS arguments for
		using probabilistic networks in general.
		<LI> <B>Q2.</B>   Should I employ an expert in The Magic Button to solve
			my problem.
		<LI> <B>A2.</B> Most likely "no". Most problems require a combination of
	  different skills, database work, systems programming,
	  Windows-UNIX interfaces, visualization, probabilistic reasoning.
	  Have the expert act as a consultant, maybe.
	</UL>

Now this is rather quickly starting to sound like I believe
no-one should be using probabilistic networks.  Course I don't
believe this.   For the following reasons.
<P>
Probabilistic networks in the broader sense are the way to address issues of
probabilistic calculation.   They are unavoidable.   If you are
addressing any problem with uncertainty (vision, image processing,
database mining, diagnosis, etc.) then you are invariably
doing something that is at least a rough approximation to probabilistic
computation.   So if your smart people are using the right tools,
then they will be using variations of probabilistic networks anyway.
The question is, whether they have been properly trained in the
more elegant framework of probabilistic networks, or whether they grind
through the same kinds of calculations on their own.   My experience
is that applications out in industry aren't solved properly because
FEW people are willing to go out and acquire the right tools
for the particular problem they are
looking at, and are rarely trained in the different neighboring fields
where they could get useful ideas.   Furthermore, experts in the
The Magic Button run around looking for applications suited for their
Magic Button, and a large pool of applications exist that require
a 5% input from The Magic Button A, another 5% from The Magic Button B,
another 5% from The Magic Button C, and then 85% of good old sweat and toil.
<P>
So instead the relevant questions are:
	<UL>
		<LI> <B>Q3.</B>  Are probabilistic networks the right tools for
			addressing uncertainty (in its many forms) ?
<P>
	 (Rhetorical question only, don't want to start THIS discussion)
		<LI> <B>Q4.</B>  If the answer to Q3 is yes, then why aren't
		probabilistic networks 
	 a basic option for all computer scientists, statisticians, etc., in
	 graduate school ?
	</UL>
	</UL>

					</TD>
				</TR>

			</Table>
		</Center>

		<P>

		<hr size=5>

		<P>

		<A name="KNOWLEDGE"></A>
		<Center>
			<Table border=5 cellspacing=10 cellpadding=10>
				<TR>
					<TH align=center valign=middle>
						Knowledge Acquisition
					</TH>
				</TR>

				<TR>
				</TR>

				<TR>
					<TD align=left valign=middle>

Edward J. Wright (<a href="mailto:EJWright@smtpgate.read.tasc.com">EJWright@smtpgate.read.tasc.com</A>) writes:

	<UL>
		<LI>
  [We tried] to encode the "rules" for some simple photo-geology
  [within a public domain expert system shell].  But I could never get it to
  work.  Later I found another expert system shell that included certainty
  factors.  I could not get that to work either.

<P>

  [I recently] used the same problem as a class project for a Bayesian network
  class.  I will emphasize that the system I built is a very simple subset of
  the photo-geology problem, but it does provide answers that are always
  reasonable and usually correct.  And I spent much less time building the
  Bayes net model then I did playing with the rule based systems.

<P>

  I think the problem was too many interrelated variables and no
  way to deal with uncertain relationships, but this was no challenge
  for the Bayesian net.

					</TD>
				</TR>

				<TR>
					<TD align=left valign=middle>

Eric Horvitz (<a href="mailto:horvitz@microsoft.com">horvitz@microsoft.com</A>) writes:

	<UL>
		<LI> [...] thought you might find reading
			[<A href="biblio.html#citeHenrion87">Henrion 87</A>]
			interesting, given your recent question on rationale for using
			influence diagrams and belief networks. [Also] a discussion of
			efficiency of knowledge acquisition and modularity and its
			implications for maintaining knowledge bases [can be found] in
			[<A href="biblio.html#citeHorvitz88">Horvitz 88</A>].
	</UL>

Russ Greiner (<A href="mailto:greiner@scr.siemens.com">greiner@scr.siemens.com</A>) writes:

	<UL>
		<LI>
   As the title suggests, the first article compares the challenge of building
   an effective diagnostic system (for the diagnosis and treatment of root
   disorders of apple trees) within first a standard rule-based expert system
   framework (ES), and then an influence diagram (ID).

		<P>

   There were several relevant findings:

	<OL>
		<LI> The two systems produced had similar graphical structures, modulo
			the directions of the links.
		<LI> While an ID can, in principle, require a great many numbers, here
			the expert had to specify only a few.  (Most of the values
			degenerated to either 0 or 1, or were determined by other values.)
			Moreover, a sensitivity analysis suggests that even rough
			assessments were usually sufficient.
		<LI> While it was easier to produce an *initial* ES than an ID (as the
	   rule-based ES requires fewer numbers, etc), the ES requires more
	   extensive testing, debugging and tuning, as the initial ES will
	   cover only the combinations that the expert explicitly anticipated.
	   This also means an ID can handle situations that the expert did
	   expect, perhaps better than the initial expert could have.
	</OL>

  The second article is also superb.  Among other things, it discusses the
  need for handling uncertainties, motivates the use of probabilities and
  decision theory, and reviews some early attempts.  It also states that
	<UL>
		<LI> "although recent research on the application of decision-science
			seems promising, for the most part only prototype systems have been
			demonstrated"
	</UL>
	</UL>

					</TD>
				</TR>

			</Table>
<A name="GENERAL">			
<Table border=5 cellspacing=10 cellpadding=10 width=100%>
	<TR><TH ALIGN=center valign=middle>
		General Discussion
	</TH></TR>
	<TR><TD>
<B>Expert Systems and Probabilistic Network Models (1997)</b><br>
          E. Castillo, J. M. Gutirrez, and A. S. Hadi.<br>
          Springer-Verlag, New York.<br><br>
Spanish version:<br>
        <b>Sistemas Expertos y Modelos de Redes Probabilsticas (1997)</b><br>
          E. Castillo, J. M. Gutirrez, and A. S. Hadi.<br>
          Monografas de la Academia Espa1ola de Ingeniera, Madrid.
	</TD></TR>
	<TR><TD>
	Symbolic Propagation Algorithms:<br><br>
<b>"Sensitivity Analysis in Discrete Bayesian Networks" (1997)</b><BR>
          E. Castillo,J.M. Gutirrez, and A.S. Hadi<br>
          IEEE Transactions on Man, Cybernetics and Systems 27(4), 403-412.<br><br>
<b>"A new Method for Symbolic Propagation in Bayesian Networks" (1996)</b><br>
          E. Castillo,J.M. Gutirrez, and A.S. Hadi<br>
          Networks 28, 31-43.
	</TD></TR>
	<tr><td>
	Learning:<br><br>
	<b>"Learning and Updating of Uncertainty in Dirichlet Models" (1997)</b><br>
          Castillo, E., Hadi, A. S., and Solares, C.<br>
          Machine Learning, in press.<br>
	</td></tr>
	<tr><td>
	Modeling Continuous and Discrete-Continuous Models:<br><br>
	<b>"Modeling Networks of Discrete and Continuous Variables with an
Application to
     Damage Assessment" (1997)</b><br>
          E. Castillo,J.M. Gutirrez, and A.S. Hadi<br>
          Multivariate Analysis, in press.<br><br>
<b>"Symbolic Propagation and Sensitivity Analysis in Gaussian Bayesian
Networks
     with Application to Damage Assessment" (1997)</b><br>
          E. Castillo,J.M. Gutirrez, and A.S. Hadi<br>
          Artificial Intelligence in Engineering 11, 173-181.
	</td></tr>
</TABLE>

</Center>

</FONT>

<hr size=5>	


<ADDRESS>
	Administrator:  Dr. Eugene Santos ---
	<A HREF="mailto:eugene@cse.uconn.edu">eugene@cse.uconn.edu</A>
<br> 
	Webmaster:  Mitchell Saba ---
		<A HREF ="mailto:saba@cse.uconn.edu">saba@cse.uconn.edu</A>
</ADDRESS>
<HR size=3>

<font size=2><i>Last Update: 
<SCRIPT LANGUAGE="JavaScript">
<!-- Begin
var days = new Array(8);
days[1] = "Sunday";
days[2] = "Monday";
days[3] = "Tuesday";
days[4] = "Wednesday";
days[5] = "Thursday";
days[6] = "Friday";
days[7] = "Saturday";
var months = new Array(13);
months[1] = "January";
months[2] = "February";
months[3] = "March";
months[4] = "April";
months[5] = "May";
months[6] = "June";
months[7] = "July";
months[8] = "August";
months[9] = "September";
months[10] = "October";
months[11] = "November";
months[12] = "December";
var dateObj = new Date(document.lastModified)
var wday = days[dateObj.getDay() + 1]
var lmonth = months[dateObj.getMonth() + 1]
var date = dateObj.getDate()
var fyear = 1900 + dateObj.getYear()
document.write(wday + ", " + lmonth + " " + date + ", " + fyear)
// End -->
</SCRIPT>
</i></font>
		
	</BODY>

</HTML>


