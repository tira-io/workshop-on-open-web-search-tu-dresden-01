<!-- <DOCUMENT>
	<FILE>
		8302785496.html
	</FILE>
	<URL>
		http://members.aol.com/JohnP71/logistic.html
	</URL>
	<TITLE>
		Logistic Regression Calculating Page
	</TITLE>
	<GENRE>
		articles
	</GENRE>
	<PLAINTEXT>
 < Logistic Regression Calculating Page Logistic Regression Revised 11/18/2003 Background ||| Techie-Stuff ||| Instructions This page performs logistic regression, in which a dichotomous (two-value) outcome is predicted by one or more variables. It generates the coefficients of a prediction formula (and standard errors of estimate and significance levels), and odds ratios (with their 95% confidence intervals). Background Info (just what is logistic regression, anyway?): Ordinary regression deals with finding a function that relates a continuous outcome variable (dependent variable y ) to one or more predictors (independent variables x 1 , x 2 , etc.). Simple linear regression assumes a function of the form: y = c 0 + c 1 * x 1 + c 2 * x 2 +... and finds the values of c 0 , c 1 , c 2 , etc. (c 0 is called the "intercept" or "constant term"). Logistic regression is a variation of ordinary regression, useful when the observed outcome is restricted to two values , which usually represent the occurrence or non-occurrence of some outcome event, (usually coded as 1 or 0, respectively). It produces a formula that predicts the probability of the occurrence as a function of the independent variables. Logistic regression fits a special s-shaped curve by taking the linear regression (above), which could produce any y -value between minus infinity and plus infinity, and transforming it with the function: p = Exp( y ) / ( 1 + Exp( y ) ) which produces p -values between 0 (as y approaches minus infinity) and 1 (as y approaches plus infinity). This now becomes a special kind of non-linear regression, which is what this page performs. Logistic regression also produces Odds Ratios (O.R.) associated with each predictor value. The odds of an event is defined as the probability of the outcome event occurring divided by the probability of the event not occurring . The odds ratio for a predictor tells the relative amount by which the odds of the outcome increase (O.R. greater than 1.0) or decrease (O.R. less than 1.0) when the value of the predictor value is increased by 1.0 units. Techie-stuff (for those who might be interested): This page contains a straightforward JavaScript implementation of a standard iterative method to minimize the Log Likelihood Function (LLF), defined as the sum of the logarithms of the predicted probabilities of occurrence for those cases where the event occurred and the logarithms of the predicted probabilities of non-occurrence for those cases where the event did not occur. Minimization is by Newton's method, with a very simple elimination algorithm to invert and solve the simultaneous equations. Central-limit estimates of parameter standard errors are obtained from the diagonal terms of the inverse matrix. Odds Ratios and their confidence limits are obtained by exponentiating the parameters and their lower and upper confidence limits (approximated by +/- 1.96 standard errors). No special convergence-acceleration techniques are used. For improved precision, the independent variables are temporarily converted to "standard scores" ( value - Mean ) / StdDev. The Null Model is used as the starting guess for the iterations -- all parameter coefficients are zero, and the intercept is the logarithm of the ratio of the number of cases with y =1 to the number with y =0. Convergence is not guaranteed, but this page should work properly with most practical problems that arise in real-world situations. This implementation has no predefined limits for the number of independent variables or cases. The actual limits are probably dependent on your web browser's available memory and other browser-specific restrictions. The fields below are pre-loaded with a very simple example. Instructions : Enter the number of data points : (or number of lines of date, if data is summarized ). Enter the number of independent variables : Indicate whether each row contains just one case, or summarized data (check here if data is summarized ). Type (or paste) the [ x , y ] data : 1,0 2,0 3,0 4,0 5,1 6,0 7,1 8,0 9,1 10,1 Use a separate row for each data point. For each row, enter the independent variable or variables (which must be numeric), followed by the dependent variable (outcome). If the data is not summarized (that is, if each row contains the values for one individual observation), then enter a single outcome number, coded as 0 (if the event did not happen) or 1 (if the event did happen). If your data is summarized (that is, if each row provides information about multiple subjects having identical predictor values), then enter the outcome as two numbers: the first is the number of subject who did not experience the event (that is, had a "0" outcome); the second is the number of subjects who did experience the event (that is, had a "1" outcome). Values should be separated by commas or tabs. You can copy data from another program, like a spreadsheet, and paste it into the window above. Click the button . The results will appear below: To print out results, copy and paste the contents of the Output window above into a word processor or text editor, then Print. For best appearance, specify a fixed-width font like Courier. Reference: Applied Logistic Regression , by D.W. Hosmer and S. Lemeshow. 1989, John Wiley &amp; Sons, New York Return to the Interactive Statistics page or to the JCP Home Page Send e-mail to John C. Pezzullo at johnp71@aol.com 
	</PLAINTEXT>
	<CONTENT>
-->
<HTML>
<HEAD>
  <META http-equiv="PICS-Label" content='(PICS-1.0 "http://www.classify.org/safesurf/" l on "1996.08.22T13:44+0000 r (SS~~000 1)'>
  <SCRIPT language="JavaScript">
<!-- hide this script tag's contents from old browsers

function Abs(x) { return Math.abs(x) }
function Sqrt(x) { return Math.sqrt(x) }
function Exp(x) { return Math.exp(x) }
function Ln(x) { return Math.log(x) }
function Power(x,n) { return Math.pow(x,n) }

var Pi = 3.141592653589793;
var PiD2 = Pi/2;

function ChiSq(x,n) {
    if(x>1000 | n>1000) { var q=Norm((Power(x/n,1/3)+2/(9*n)-1)/Sqrt(2/(9*n)))/2; if (x>n) {return q}{return 1-q} }
    var p=Math.exp(-0.5*x); if((n%2)==1) { p=p*Math.sqrt(2*x/Pi) }
    var k=n; while(k>=2) { p=p*x/k; k=k-2 }
    var t=p; var a=n; while(t>1e-15*p) { a=a+2; t=t*x/a; p=p+t }
    return 1-p
    }

function Norm(z) { var q=z*z
    if(Abs(z)>7) {return (1-1/q+3/(q*q))*Exp(-q/2)/(Abs(z)*Sqrt(PiD2))} {return ChiSq(q,1) }
    }

function Fmt(x) { var v;
	if(x>=0) { v='          '+(x+0.00005) } else { v='          '+(x-0.00005) }
	v = v.substring(0,v.indexOf('.')+5)
	return v.substring(v.length-10,v.length)
	}

function Fmt3(x) { var v;
	v = "   " + x;
	return v.substring(v.length-3,v.length)
	}

function Fmt9(x) { var v;
	v = "         " + x;
	return v.substring(v.length-9,v.length)
	}

function vFmt(x) { var v;
	if(x>=0) { v='              '+(x+0.0000005) } else { v='          '+(x-0.0000005) }
	v = v.substring(0,v.indexOf('.')+7)
	return v.substring(v.length-14,v.length)
	}

function Xlate(s,from,to) { var v = s;
	var l=v.indexOf(from);
	while(l>-1) {
		v = v.substring(0,l) + to + v.substring(l+1,v.length);
		l=v.indexOf(from)
		}
	return v
    }

function crArr(n) {
	this.length = n
	for (var i = 0; i < this.length; i++) { this[i] = 0 }
	}
	
function ix(j,k,nCols) { return j * nCols + k }

var CR = unescape("%0D");
var LF = unescape("%0A");
var Tb = unescape("%09");
var NL = CR + LF;

function Iterate(form) {

var i = 0; var j = 0; var k = 0; var l = 0;

var nC   = eval(form.cPts.value);
var nR   = eval(form.cVar.value);
var nP   = nR + 1;
var nP1  = nP + 1;
var sY0 = 0;
var sY1 = 0;
var sC = 0;

var X    = new crArr( nC * ( nR + 1 ) );
var Y0   = new crArr( nC );
var Y1   = new crArr( nC );
var xM   = new crArr( nR + 1 );
var xSD  = new crArr( nR + 1 );
var Par  = new crArr( nP );
var SEP  = new crArr( nP );
var Arr  = new crArr( nP * nP1 );

var da = Xlate(form.data.value,Tb,",");
form.data.value = da;
if( da.indexOf(NL)==-1 ) { if( da.indexOf(CR)>-1 ) { NL = CR } else { NL = LF } }

for (i = 0; i<nC; i++) {
	X[ix(i,0,nR+1)] = 1;
	l = da.indexOf(NL); if( l==-1 ) { l = da.length };
	var v = da.substring(0,l);
	da = da.substring(l+NL.length,da.length);
	for (j = 1; j<=nR; j++) {
		l = v.indexOf(","); if( l==-1 ) { l = v.length };
		x = eval(v.substring(0,l))
		X[ix(i,j,nR+1)] = x;
		v = v.substring(l+1,v.length);
		}
	if(form.Grouped.checked=="1")
		{
		l = v.indexOf(","); if( l==-1 ) { l = v.length };
		x = eval(v.substring(0,l))
		Y0[i] = x; sY0 = sY0 + x;
		v = v.substring(l+1,v.length);
		l = v.indexOf(","); if( l==-1 ) { l = v.length };
		x = eval(v.substring(0,l))
		Y1[i] = x; sY1 = sY1 + x;
		v = v.substring(l+1,v.length);
		}
		else
		{
		x = eval(v.substring(0,l));
		if ( x==0 ) { Y0[i] = 1; sY0 = sY0 + 1 } else { Y1[i] = 1; sY1 = sY1 + 1 }
		}
	sC = sC + (Y0[i] + Y1[i]);
	for (j = 1; j<=nR; j++) {
		x = X[ix(i,j,nR+1)];
		xM[j] = xM[j] + (Y0[i] + Y1[i])*x;
		xSD[j] = xSD[j] + (Y0[i] + Y1[i])*x*x;
		}
	}

var o = "Descriptives..." + NL;

o = o + ( NL + sY0 + " cases have Y=0; " + sY1 + " cases have Y=1." + NL );

o = o + ( NL + " Variable     Avg       SD    " + NL );
for (j = 1; j<=nR; j++) {
	xM[j]  = xM[j]  / sC;
	xSD[j] = xSD[j] / sC;
	xSD[j] = Sqrt( Abs( xSD[j] - xM[j] * xM[j] ) )
	o = o + (  "   " + Fmt3(j) + "    " + Fmt(xM[j]) + Fmt(xSD[j])+ NL );
	}
xM[0] = 0; xSD[0] = 1;

for (i = 0; i<nC; i++) {
	for (j = 1; j<=nR; j++) {
		X[ix(i,j,nR+1)] = ( X[ix(i,j,nR+1)] - xM[j] ) / xSD[j];
		}
	}

o = o + ( NL + "Iteration History..." );
form.output.value = o;

Par[0] = Ln( sY1 / sY0 );
for (j = 1; j<=nR; j++) {
	Par[j] = 0;
	}

var LnV = 0; var Ln1mV = 0;

var LLp = 2e+10;
var LL  = 1e+10;

while( Abs(LLp-LL)>0.0000001 ) {
	LLp = LL;
	LL = 0;
	for (j = 0; j<=nR; j++) {
		for (k = j; k<=nR+1; k++) {
			Arr[ix(j,k,nR+2)] = 0;
			}
		}
	
	for (i = 0; i<nC; i++) {	
		var v = Par[0];
		for (j = 1; j<=nR; j++) {
			v = v + Par[j] * X[ix(i,j,nR+1)];
			}
		if( v>15 ) { LnV = -Exp(-v); Ln1mV = -v; q = Exp(-v) }
			{ if( v<-15 ) {	LnV = v; Ln1mV = -Exp(v); q = Exp(v) }
				{ v = 1 / ( 1 + Exp(-v) ); LnV = Ln(v); Ln1mV = Ln(1-v); q = v*(1-v) }
			}
		LL = LL - 2*Y1[i]*LnV - 2*Y0[i]*Ln1mV;
		for (j = 0; j<=nR; j++) {
			var xij = X[ix(i,j,nR+1)];
			Arr[ix(j,nR+1,nR+2)] = Arr[ix(j,nR+1,nR+2)] + xij * ( Y1[i] * (1 - v) + Y0[i] * (-v) );
			for (k=j; k<=nR; k++) {
				Arr[ix(j,k,nR+2)] = Arr[ix(j,k,nR+2)] + xij * X[ix(i,k,nR+1)] * q * (Y0[i] + Y1[i]);
				}
			}
		}

	o = o + ( NL + "-2 Log Likelihood = " + Fmt( LL ) );
	if( LLp==1e+10 ) { LLn = LL; o = o + " (Null Model)" }
	form.output.value = o;

	for (j = 1; j<=nR; j++) {
		for (k=0; k<j; k++) {
			Arr[ix(j,k,nR+2)] = Arr[ix(k,j,nR+2)];
			}
		}

	for (i=0; i<=nR; i++) { var s = Arr[ix(i,i,nR+2)]; Arr[ix(i,i,nR+2)] = 1;
		for (k=0; k<=nR+1; k++) { Arr[ix(i,k,nR+2)] = Arr[ix(i,k,nR+2)] / s; }
		for (j=0; j<=nR; j++) {
			if (i!=j) { s = Arr[ix(j,i,nR+2)]; Arr[ix(j,i,nR+2)] = 0;
				for (k=0; k<=nR+1; k++) {
					Arr[ix(j,k,nR+2)] = Arr[ix(j,k,nR+2)] - s * Arr[ix(i,k,nR+2)];
					}
				}
			}
		}

	for( j=0; j<=nR; j++) {
		Par[j] = Par[j] + Arr[ix(j,nR+1,nR+2)];
		}

	}

o = o + ( " (Converged)" + NL );
var CSq = LLn - LL;
o = o + ( NL + "Overall Model Fit..." + NL + "  Chi Square=" + Fmt(CSq) + ";  df=" + nR + ";  p=" + Fmt(ChiSq(CSq,nR)) + NL );

o = o + ( NL + "Coefficients and Standard Errors..." + NL );
o = o + ( " Variable     Coeff.    StdErr       p" + NL );
for( j=1; j<=nR; j++) {
	Par[j] = Par[j] / xSD[j];
	SEP[j] = Sqrt( Arr[ix(j,j,nP+1)] ) / xSD[j];
	Par[0] = Par[0] - Par[j] * xM[j];
	o = o + ( "   " + Fmt3(j) + "    " + Fmt(Par[j]) + Fmt(SEP[j]) + Fmt( Norm(Abs(Par[j]/SEP[j])) ) + NL );
	}
o = o + ( "Intercept " + Fmt(Par[0]) + NL );

o = o + ( NL + "Odds Ratios and 95% Confidence Intervals..." + NL );
o = o + ( " Variable      O.R.      Low  --  High" + NL );
for( j=1; j<=nR; j++) {
	var ORc = Exp( Par[j] );
	var ORl = Exp( Par[j] - 1.96 * SEP[j] );
	var ORh = Exp( Par[j] + 1.96 * SEP[j] );
	o = o + ( "   " + Fmt3(j) + "    " + Fmt(ORc) + Fmt(ORl) + Fmt(ORh) + NL + NL );
	}

for (j = 1; j<=nR; j++) {
	v = "          X" + j;
	o = o + v.substring(v.length-10,v.length);
	}
if(form.Grouped.checked=="1")
	{ o = o + ( "           n0           n1 Calc Prob" + NL ) }
	else
	{ o = o + ( "            Y Calc Prob" + NL ) }
for (i = 0; i<nC; i++) {	
	v = Par[0];
	for (j = 1; j<=nR; j++) {
		x = xM[j] + xSD[j] * X[ix(i,j,nR+1)];
		v = v + Par[j] * x;
		o = o + Fmt(x);
		}
	v = 1 / ( 1 + Exp( -v ) );
	if(form.Grouped.checked=="1")
		{ o = o + ( "    " + Fmt9(Y0[i]) + "    " + Fmt9(Y1[i]) + Fmt(v) + NL ) }
		else
		{ o = o + ( "    " + Fmt9(Y1[i]) + Fmt(v) + NL ) }
	}

form.output.value = o;

}		

<!-- done hiding from old browsers -->
</SCRIPT>
  <TITLE>Logistic Regression Calculating Page</TITLE>
</HEAD>
<BODY BGCOLOR="#ffffee">
<CENTER>
  <H2>
    <FONT COLOR="Red">Logistic Regression</FONT>
  </H2>
  <P>
  <SMALL><I>Revised 11/18/2003</I></SMALL>
  <P>
  <A HREF="#Background">Background</A> ||| <A HREF="#Techie">Techie-Stuff</A>
  ||| <A HREF="#Instructions">Instructions</A>
</CENTER>
<P>
This page performs logistic regression, in which a dichotomous (two-value)
outcome is predicted by one or more variables. It generates the coefficients
of a prediction formula (and standard errors of estimate and significance
levels), and odds ratios (with their 95% confidence intervals).
<P>
  <HR>
<H3>
  <FONT COLOR="Red"><A NAME="Background">Background Info</A> (just what is
  logistic regression, anyway?):</FONT>
</H3>
<P>
<B>Ordinary</B> regression deals with finding a function that relates a
<B>continuous</B> outcome variable (dependent variable <I>y</I>) to one or
more predictors (independent variables <I>x</I><SUB>1</SUB>,
<I>x</I><SUB>2</SUB>, etc.). Simple linear regression assumes a function
of the form:<BR>
<I>y</I> = c<SUB>0</SUB> + c<SUB>1</SUB> * <I>x</I><SUB>1</SUB> +
c<SUB>2</SUB> * <I>x</I><SUB>2</SUB> +...<BR>
and finds the values of c<SUB>0</SUB>, c<SUB>1</SUB>, c<SUB>2</SUB>, etc.
(c<SUB>0</SUB> is called the "intercept" or "constant term").
<P>
<B>Logistic</B> regression is a variation of ordinary regression, useful
when the observed outcome is <B>restricted to two values</B>, which usually
represent the occurrence or non-occurrence of some outcome event, (usually
coded as 1 or 0, respectively). It produces a formula that predicts the
<B>probability of the occurrence</B> as a function of the independent variables.
<P>
Logistic regression fits a special s-shaped curve by taking the linear regression
(above), which could produce any <I>y</I>-value between minus infinity and
plus infinity, and transforming it with the function:<BR>
<I>p</I> = Exp(<I>y</I>) / ( 1 + Exp(<I>y</I>) )<BR>
which produces <I>p</I>-values between 0 (as <I>y</I> approaches minus infinity)
and 1 (as <I>y</I> approaches plus infinity). This now becomes a special
kind of <I>non-linear</I> regression, which is what this page performs.
<P>
Logistic regression also produces <I>Odds Ratios</I> (O.R.) associated with
each predictor value. The <I>odds</I> of an event is defined as the probability
of the outcome event <B>occurring</B> divided by the probability of the event
<B>not occurring</B>. The odds ratio for a predictor tells the relative amount
by which the odds of the outcome increase (O.R. greater than 1.0) or decrease
(O.R. less than 1.0) when the value of the predictor value is increased by
1.0 units.
<P ALIGN=Left>
  <HR>
<H3>
  <P ALIGN=Left>
  <FONT COLOR="Red"><A NAME="Techie">Techie-stuff</A> (for those who might
  be interested):</FONT>
</H3>
<P>
This page contains a straightforward <I>JavaScript</I> implementation of
a standard iterative method to minimize the Log Likelihood Function (LLF),
defined as the sum of the logarithms of the predicted probabilities of occurrence
for those cases where the event occurred and the logarithms of the predicted
probabilities of non-occurrence for those cases where the event did not occur.
<P>
Minimization is by Newton's method, with a very simple elimination algorithm
to invert and solve the simultaneous equations. Central-limit estimates of
parameter standard errors are obtained from the diagonal terms of the inverse
matrix. Odds Ratios and their confidence limits are obtained by exponentiating
the parameters and their lower and upper confidence limits (approximated
by +/- 1.96 standard errors).
<P>
No special convergence-acceleration techniques are used. For improved precision,
the independent variables are temporarily converted to "standard scores"
( value - Mean ) / StdDev. The <I>Null Model</I> is used as the starting
guess for the iterations -- all parameter coefficients are zero, and the
intercept is the logarithm of the ratio of the number of cases with
<I>y</I>=1 to the number with <I>y</I>=0. Convergence is not guaranteed,
but this page should work properly with most practical problems that arise
in real-world situations.
<P>
This implementation has no predefined limits for the number of independent
variables or cases. The actual limits are probably dependent on your web
browser's available memory and other browser-specific restrictions.
<P>
The fields below are pre-loaded with a very simple example.
<P>
  <HR>
<FORM method=post>
  <H3>
    <FONT COLOR="Red"><A NAME="Instructions">Instructions</A>:</FONT>
  </H3>
  <OL>
    <LI>
      Enter the <FONT COLOR="Red">number of data points</FONT>:
      <INPUT TYPE="text" NAME="cPts" VALUE="10" SIZE="4"> (or number of lines of
      date, if data is <I>summarized</I>).
    <LI>
      Enter the <FONT COLOR="Red">number of independent variables</FONT>:
      <INPUT TYPE="text" NAME="cVar" value="1" SIZE="2">
    <LI>
      Indicate whether <FONT COLOR="Red">each row contains just one case, or summarized
      data</FONT> (check 
      <INPUT TYPE="checkbox" NAME="Grouped" VALUE="1">here if data is
      <I>summarized</I>).
    <LI>
      Type (or paste) the <FONT COLOR="Red">[<I>x</I>,<I>y</I>] data</FONT>:<BR>
      <TEXTAREA NAME="data" ROWS="8" COLS="50">1,0
2,0
3,0
4,0
5,1
6,0
7,1
8,0
9,1
10,1
</TEXTAREA><BR>
      <FONT COLOR="Purple"><SMALL>Use a separate row for each data point. For each
      row, enter the <I>independent</I> variable or variables (which must be numeric),
      followed by the <I>dependent</I> variable (outcome). <BR>
      If the data is not summarized (that is, if each row contains the values for
      one individual observation), then enter a single outcome number, coded as
      0 (if the event <B>did not</B> happen) or 1 (if the event <B>did</B>
      happen).<BR>
      If your data is <B>summarized</B> (that is, if each row provides information
      about multiple subjects having identical predictor values), then enter the
      outcome as two numbers: the first is the number of subject who <B>did not</B>
      experience the event (that is, had a "0" outcome); the second is the number
      of subjects who <B>did</B> experience the event (that is, had a "1"
      outcome).<BR>
      Values should be separated by commas or tabs. You can copy data from another
      program, like a spreadsheet, and paste it into the window
      above.</SMALL></FONT>
    <LI>
      <FONT COLOR="Red">Click the
      <INPUT TYPE="button" VALUE="Solve" onClick=Iterate(this.form)> button</FONT>.
      The results will appear below:<BR>
      <TEXTAREA NAME="output" ROWS="10" COLS="50"></TEXTAREA><BR>
    <LI>
      To print out results, copy and paste the contents of the Output window above
      into a word processor or text editor, then Print. For best appearance, specify
      a fixed-width font like Courier.
  </OL>
  <P>
    <HR>
  <P>
  Reference: <I>Applied Logistic Regression</I>, by D.W. Hosmer and S. Lemeshow.
  1989, John Wiley &amp; Sons, New York
  <P ALIGN=Center>
    <HR>
  <BR>
  Return to the <A href ="javastat.html">Interactive Statistics page</A> or
  to the <A HREF="index.html">JCP Home Page</A><BR>
  <BR>
  Send e-mail to John C. Pezzullo at
  <A href ="mailto:johnp71@aol.com">johnp71@aol.com</A>
</FORM>
</BODY></HTML>

